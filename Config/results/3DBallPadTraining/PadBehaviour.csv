Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,1.4204248,36.011843079200595,0.2408998,2.601185094868695,2.601185094868695,0.50326586,0.024487983,0.0002846087,0.19486955,0.00474399,1.0
100000,1.4190419,59.48609431680774,1.0758299,4.945828456796498,4.945828456796498,0.52364147,0.0244256,0.00025688187,0.18562728,0.0042828014,1.0
150000,1.41218,104.04631578947368,2.0987692,9.395168641222124,9.395168641222124,0.74123156,0.026332755,0.00022610466,0.17536822,0.003770873,1.0
200000,1.4028342,166.51839464882943,3.1220593,15.618121969619853,15.618121969619853,0.7804619,0.022641124,0.00019527152,0.16509046,0.0032580148,1.0
